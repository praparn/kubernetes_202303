Instruction for Workshop 2.4 Kubernetes Security:
Note: This instruction will start lab for kubernetes's cluster for real workshop:
============================================================================================================================================================
Part 1: Network Policy
============================================================================================================================================================
1. Create Application Set by command:
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/management-ui-set.yml
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/backend-set.yml
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/frontend-set.yml
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/client-set.yml

2. Check Namespace / Service / Pods 
	kubectl get namespace
	kubectl get all -n=management-ui 
	kubectl get all -n=stars
	kubectl get all -n=client

3. Test open browser for check application:
	http://<Public IP>:32500

4. Apply network policy for denied any connection to namespace: "stars" and "client"
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/policy-deny-client.yml
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/policy-deny-stars.yml

5. Test open browser again:
	http://<Public IP>:32500

6. Apply network policy for allow all pods from namespace "management-ui" (label: role=management-ui) access to any pods in namespace "stars"
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/policy-allow-ui.yml

7. Apply network policy for allow all pods from namespace "management-ui" (label: role=management-ui) access to any pods in namespace "client"
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/policy-allow-ui-client.yml

8. Test open browser again:
	http://<Public IP>:32500

9. Apply network policy for allow pods frontend (label: role=frontend) to pods backend (label: role=backend) in same namespace
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/policy-allow-backend.yml

10. Apply network policy for allow all pods from namespace "client" (label: role=client) access to pods frontend (label: role=frontend)
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/policy-allow-frontend.yml

11. Test open browser again:
	http://<Publi IP>:32500

12. CleanUp Lab by command:
	kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/management-ui-set.yml
	kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/backend-set.yml
	kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/frontend-set.yml
	kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/client-set.yml

============================================================================================================================================================
Part 2: Access Control Policy (User Account)
============================================================================================================================================================

1. Create namespace "security" and deploy application via command:
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-namespace.yml
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-pod.yml
	kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-svc.yml
	kubectl get pod,svc -n=security
	curl http://<Private IP>:32500

2. Configure Openssl and Create private key for new user account
cd ~
sudo sed -i '/RANDFILE/d' /etc/ssl/openssl.cnf
openssl genrsa -out labreadonly.key 2048

3. Create CSR from private key (User: labreadonly, OU: labdockerthailand)
openssl req -new -key labreadonly.key -out labreadonly.csr -subj "/CN=labreadonly/O=labdockerthailand"

4. Generate Certificate base on CSR with aging 365 days
sudo openssl x509 -req -in labreadonly.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out labreadonly.crt -days 365

5. Private key and Public key will place on /home/ubuntu (~)
ls ~/labreadonly*

6. Setup credential context via kubectl by command:
cd ~
cp ~/.kube/config ~/.kube/config_backup
kubectl config set-credentials labreadonly --client-certificate=/home/ubuntu/labreadonly.crt  --client-key=/home/ubuntu/labreadonly.key
kubectl config set-context labreadonly-context --cluster=kuberneteslab --namespace=security --user=labreadonly

7. Test use credential for operate by command: (Expect: Forbidden)
kubectl --context=labreadonly-context get pods

8. Create Role "ReadOnly" by command:
kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-role-readonly.yml
kubectl get roles -n=security

9. Create RoleBinding for user "labreadonly" with role "rolereadonly"
kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-rolebinding-labsecurity.yml
kubectl get rolebinding -n=security

10. Try to get pods again.
kubectl --context=labreadonly-context get pods

11. Try to get svc,delete pods/create new pods: (Expect: Forbidden)
kubectl --context=labreadonly-context get svc
kubectl --context=labreadonly-context delete pods/webtest
kubectl --context=labreadonly-context run webtest --image=labdocker/nginx:http2 --port=443 -n=security

12. CleanUp Lab:
kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-rolebinding-labsecurity.yml
kubectl config delete-context labreadonly-context

============================================================================================================================================================
Part 3: Access Control Policy (System Account)
============================================================================================================================================================
1. Create Service Account by command:
kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-serviceaccount-readonly.yml
kubectl get sa -n=security

2. Create RoleBinding by command:
kubectl create rolebinding rolebindingserviceaccountreadonly \
  --role=rolereadonly \
  --serviceaccount=security:serviceaccount-readonly \
  --namespace=security

3. Test Service Account by command:
kubectl get pods -n security --as system:serviceaccount:security:serviceaccount-readonly
kubectl get svc -n security --as system:serviceaccount:security:serviceaccount-readonly
kubectl run webtest --image=labdocker/nginx:http2 --port=443 -n security --as system:serviceaccount:security:serviceaccount-readonly

4. Clearup Lab by command:
kubectl delete rolebinding/rolebindingserviceaccountreadonly -n=security
kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-serviceaccount-readonly.yml
kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-role-readonly.yml
kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-pod.yml
kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-svc.yml
kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/security-namespace.yml

============================================================================================================================================================
Part 4: Pods Security Association (PSA)
============================================================================================================================================================
1. Create Namespace with enforce PSA by command:
kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/psa-namespace.yml

2. Check detail of namespace by command:
kubectl describe namespace/namespace-psa
*Remark: As current 1.23 version. PSA is still same with 1.22 policy just shift to beta

3. Create deployment pods with hostpath (Expect: Failure by enforce/baseline) by command:
kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/psa-hostpath-pods.yml

4. Create deployment with standard pods by command (Expect: Get warning message by warning/restrict):
kubectl create -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/psa-normal-pods.yml

5. Access to pods and check user id and file permission by command:
kubectl get pods -n=namespace-psa
kubectl exec -it alpineweb sh -n=namespace-psa
ps 											==> record USER
mkdir /data && touch /data/testfile			
ls /data/ 									
ping 1.1.1.1
apk update && apk add curl
curl https://www.google.com
id 											==> record ID
exit

6. CleanUp Lab by command:
kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/psa-normal-pods.yml
kubectl delete -f https://raw.githubusercontent.com/praparn/kubernetes_202205/master/WorkShop_2.4_Security/psa-namespace.yml